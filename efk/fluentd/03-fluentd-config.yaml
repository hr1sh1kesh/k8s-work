---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd
  namespace: kube-system
data:
  fluent.conf: |
   <source>
     @type systemd
     path /var/log/journal
     filters [{ "_SYSTEMD_UNIT": "docker.service" }]
     pos_file /tmp/docker-service.pos
     tag journal.dockerd
     read_from_head true
     strip_underscores true
   </source>

    <source>
      @type systemd
      path /var/log/journal
      filters [{ "_SYSTEMD_UNIT": "kubelet.service" }]
      pos_file /tmp/k8s-kubelet.pos
      tag journal.kubelet
      read_from_head true
      strip_underscores true
    </source>

    <source>
      type tail
      path /var/log/containers/portworx*.log
      pos_file /tmp/px-container.log.pos
      time_format %Y-%m-%dT%H:%M:%S.%N
      tag portworx.*
      format json
      read_from_head true
      keep_time_key true
    </source>

    <filter portworx.**>
      @type rename_key
      rename_rule3 kubernetes.host hostname
    </filter>

    <filter journal.kubelet.**>
      @type rename_key
      rename_rule1 MESSAGE log
      rename_rule2 HOSTNAME hostname
    </filter>

    <filter journal.dockerd.**>
      @type rename_key
      rename_rule1 MESSAGE log
      rename_rule2 HOSTNAME hostname
    </filter>

    <filter **>
      type kubernetes_metadata
    </filter>

    <match journal.dockerd.**>
      @type copy
      <store>
          @type s3
          aws_key_id #AWS_KEY_ID#
          aws_sec_key #AWS_SECRET_KEY_ID#
          s3_bucket #S3_BUCKET#
          s3_region #S3_REGION#
          path logs/
          buffer_path /var/log/journal-dockerd/s3
          s3_object_key_format #indexUUID#_%{path}%{time_slice}_%{index}.%{file_extension}          
          time_slice_format %Y%m%d%H
          time_slice_wait 3m
          utc
          buffer_chunk_limit 256m
      </store>
      <store>
          type elasticsearch_dynamic
          log_level info
          include_tag_key false
          logstash_prefix #indexUUID#.journal.dockerd ## Prefix for creating an Elastic search index.
          host #ELASTICSEARCH_HOST# ## Hostname of the ES cluster.
          port #ELASTICSEARCH_PORT#
          user #FLUENT_USER#
          password #FLUENT_PASSWORD# Enter the password for the user to connect to ES
          logstash_format true
          buffer_chunk_limit 2M
          buffer_queue_limit 32
          flush_interval 30s  # flushes events ever minute. Can be configured as needed.
          max_retry_wait 30
          disable_retry_limit
          num_threads 2
       </store>
    </match>

    <match journal.kubelet.**>
      @type copy
      <store>
          @type s3
          aws_key_id #AWS_KEY_ID#
          aws_sec_key #AWS_SECRET_KEY_ID#
          s3_bucket #S3_BUCKET#
          s3_region #S3_REGION#
          path logs/
          buffer_path /var/log/journal-kubelet/s3
          s3_object_key_format #indexUUID#_%{path}%{time_slice}_%{index}.%{file_extension}          
          time_slice_format %Y%m%d%H
          time_slice_wait 3m
          utc
          buffer_chunk_limit 256m
      </store>
      <store>
          type elasticsearch_dynamic
          log_level info
          include_tag_key false
          logstash_prefix #indexUUID#.journal.kubelet ## Prefix for creating an Elastic search index.
          host #ELASTICSEARCH_HOST# ## Hostname of the ES cluster.
          port #ELASTICSEARCH_PORT#
          user #FLUENT_USER#
          password #FLUENT_PASSWORD# #Enter the password for the user to connect to ES
          logstash_format true
          buffer_chunk_limit 2M
          buffer_queue_limit 32
          flush_interval 30s  # flushes events ever minute. Can be configured as needed.
          max_retry_wait 30
          disable_retry_limit
          num_threads 2
       </store>
    </match>

    <match portworx.**>
      @type copy
      <store>
          @type s3
          aws_key_id #AWS_KEY_ID#
          aws_sec_key #AWS_SECRET_KEY_ID#
          s3_bucket #S3_BUCKET#
          s3_region #S3_REGION#
          path logs/
          buffer_path /var/log/px-container/s3
          s3_object_key_format #indexUUID#_%{path}%{time_slice}_%{index}.%{file_extension}          
          time_slice_format %Y%m%d%H
          time_slice_wait 1m
          utc
          buffer_chunk_limit 256m
      </store>
      <store>
          type elasticsearch_dynamic
          log_level info
          include_tag_key false
          logstash_prefix #indexUUID#.portworx-logs ## Prefix for creating an Elastic search index.
          host #ELASTICSEARCH_HOST# ## Hostname of the ES cluster.
          port #ELASTICSEARCH_PORT#
          user #FLUENT_USER#
          password #FLUENT_PASSWORD# #Enter the password for the user to connect to ES
          logstash_format true
          buffer_chunk_limit 2M
          buffer_queue_limit 32
          flush_interval 30s  # flushes events ever minute. Can be configured as needed.
          max_retry_wait 30
          disable_retry_limit
          num_threads 2
      </store>
    </match>    
---
